{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genomelab/esFunctions/blob/master/1_Segment_Image_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHJ3v3K_27WE"
      },
      "outputs": [],
      "source": [
        "#pip install DeepCell\n",
        "#pip install git+https://github.com/angelolab/mibi-bin-tools.git@v0.2.5\n",
        "#pip install ark-analysis\n",
        "#pip install imagecodecs\n",
        "#pip install ark-utils\n",
        "#pip install numpy==1.23.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnhh4rVF2pDy"
      },
      "source": [
        "### Restart the Runtime after installing modules.\n",
        "### This is a notebook to format your data for segmentation, run the images through the cloud instance of Mesmer, and then extract marker counts and morphological information from all the cells in your images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#name of file to download and name of the project\n",
        "# It also creates a small version of the files in proejct_name with small added to it\n",
        "filename = 'NBL_N0351_Scan1.qptiff'\n",
        "project_name = 'neuroblastoma'\n",
        "project_base_dir = \"../data/\" + project_name\n",
        "\n",
        "\n",
        "project_name_small = project_name + \"_small\"\n",
        "project_small_base_dir = \"../data/\" + project_name_small\n",
        "\n",
        "#coordinates of image to extract for small image\n",
        "x1 = 20000\n",
        "y1 = 25000\n",
        "x2 = 20500\n",
        "y2 = 25500\n"
      ],
      "metadata": {
        "id": "xn92IPSdjF1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvslz8hK2pDz"
      },
      "outputs": [],
      "source": [
        "# import required packages\n",
        "# import required packages\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import xarray as xr\n",
        "from alpineer import io_utils\n",
        "\n",
        "from ark.segmentation import marker_quantification, segmentation_utils\n",
        "from ark.utils import (deepcell_service_utils, example_dataset,\n",
        "                       plot_utils)\n",
        "import imagecodecs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKf8w6Hw2pD0"
      },
      "source": [
        "## 0: Set root directory and download example dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdXdx1Jm2pD0"
      },
      "source": [
        "Here we are using the example data located in `/data/example_dataset/input_data`. To modify this notebook to run using your own data, simply change `base_dir` to point to your own sub-directory within the data folder.\n",
        "\n",
        "* `base_dir`: the path to all of your imaging data. This directory will contain all of the data generated by this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R6XvIjh-fCo"
      },
      "outputs": [],
      "source": [
        "## This works only with google colab on google machines if runningn locally need to connect via pydrive \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from pydrive2.fs import GDriveFileSystem\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "gauth.LocalWebserverAuth()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaELkx8S2pD0"
      },
      "source": [
        "If you would like to test the features in Ark with an example dataset, run the cell below. It will download a dataset consisting of 11 FOVs with 22 channels. You may find more information about the example dataset in the [README](../README.md#example-dataset).\n",
        "\n",
        "If you are using your own data, skip the cell below.\n",
        "\n",
        "* `overwrite_existing`: If set to `False`, it will not overwrite existing data in the `data/example_dataset`. Recommended leaving as `True` if you are doing a clean run of the `ark` pipeline using this dataset from the start. If you already have the dataset downloaded, set to `False`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehiu7HCi2pD0"
      },
      "source": [
        "## 1: set file paths and parameters\n",
        "\n",
        "### All data, images, files, etc. must be placed in the 'data' directory, and referenced via '../data/path_to_your_data'\n",
        "\n",
        "If you're interested in directly interfacing with Google Drive, consult the documentation [here](https://ark-analysis.readthedocs.io/en/latest/_rtd/google_docs_usage.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUE36-Qo2pD0"
      },
      "outputs": [],
      "source": [
        "# set up file paths\n",
        "# set up the base directory\n",
        "base_dir = projcet_base_dir\n",
        "cell_table_dir = os.path.join(base_dir, \"segmentation/cell_table\")\n",
        "deepcell_input_dir = os.path.join(base_dir, \"segmentation/deepcell_input\")\n",
        "deepcell_output_dir = os.path.join(base_dir, \"segmentation/deepcell_output\")\n",
        "deepcell_visualization_dir = os.path.join(base_dir, \"segmentation/deepcell_visualization\")\n",
        "\n",
        "# create directories if do not exist\n",
        "for directory in [cell_table_dir, tiff_dir, deepcell_input_dir, deepcell_output_dir, deepcell_visualization_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# validate paths\n",
        "io_utils.validate_paths([base_dir,\n",
        "                         tiff_dir,\n",
        "                         deepcell_input_dir,\n",
        "                         deepcell_output_dir,\n",
        "                         cell_table_dir,\n",
        "                         deepcell_visualization_dir\n",
        "                         ])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the image file \n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#file_list = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList()\n",
        "#for file1 in file_list:\n",
        "#  print('title: %s, id: %s, Mimetype: %s' % (file1['title'], file1['id'], file1['mimeType']))\n",
        "\n",
        "# Image file name\n",
        "\n",
        "\n",
        "download_file = os.path.join(base_dir, filename)\n",
        "\n",
        "# Query\n",
        "query1 = {'q' : f\"mimeType = 'image/tiff'\"}\n",
        "query2 = {'q': f\"title = '{filename}'\"}\n",
        "\n",
        "# Get list of files that match against the query1 for tiff files if needed\n",
        "#tiff_files = drive.ListFile(query1).GetList()\n",
        "#for file1 in tiff_files:\n",
        "#  print('List of Files: %s, id: %s, Mimetype: %s' % (file1['title'], file1['id'], file1['mimeType']))\n",
        "\n",
        "myfiles = drive.ListFile(query2).GetList()\n",
        "print('File to download: %s, id: %s, Mimetype: %s' % (myfiles[0]['title'], myfiles[0]['id'], myfiles[0]['mimeType']))\n",
        "\n",
        "\n",
        "img_file = drive.CreateFile(myfiles[0])\n",
        "img_file.GetContentFile(download_file, remove_bom=True) \n",
        "## fsspec connection did not work.  abandoened it\n",
        "#fs = GDriveFileSystem(\"root\", gauth)\n",
        "#fs.listdir(\"root\")\n",
        "#f = fs.open('root/NBL_N0351_Scan1.qptiff')\n"
      ],
      "metadata": {
        "id": "TV-KPFavk1Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFI7pXVX2pD1"
      },
      "outputs": [],
      "source": [
        "import tifffile as tif\n",
        "\n",
        "### Shahab Asgharzadeh - Feb 2023\n",
        "### Takes OME-TIFF or QPTIFF file and seperates channels and saves them in a fov folder under tiff_dir folder \n",
        "### - optional create square chunks given a size (max for DeepLearn Kiosk is 2048x2048) \n",
        "### - saves the chunks under seperate fov files (fov0, fov1, etc.)\n",
        "### - images are saved based on channel names provided (order needs to be correct)\n",
        "\n",
        "\n",
        "chunk_size = 0\n",
        "channel_names = [ 'DAPI', 'CD45R0', 'CD31', 'CD4', 'CD8', 'CD20', 'CD3', 'Ki67','PanCK', \n",
        "'PCNA', 'CD163', 'PDL1', 'CD14']\n",
        "\n",
        "\n",
        "def convert_ome_tiff_to_channels(input_file, chunk_size):\n",
        "    # Open the OME-TIFF file and get the number of channels\n",
        "    with tif.TiffFile(input_file) as tif_file:\n",
        "        channel_count = tif_file.series[0].shape[0]\n",
        "\n",
        "    # Loop over each channel and save it as a separate TIFF file\n",
        "    # If Chunk size other than 0 given, it will create regions of interest as square for\n",
        "    # entire image for each channel in seperate directories. \n",
        "    \n",
        "    for channel_index in range(channel_count):\n",
        "        # Get the output filename for the current channel\n",
        "        if chunk_size == 0:\n",
        "            FOV_dir = os.path.join(tiff_dir, \"fov0\")\n",
        "            if not os.path.exists(FOV_dir):\n",
        "                os.makedirs(FOV_dir)\n",
        "                io_utils.validate_paths([FOV_dir])\n",
        "            output_filename = os.path.join(FOV_dir,(f'{channel_names[channel_index]}.tiff'))\n",
        "\n",
        "            # Open the OME-TIFF file and extract the image data for the current channel\n",
        "            with tif.TiffFile(input_file) as tif_file:\n",
        "                channel_image_data = tif_file.asarray(key=channel_index)\n",
        "\n",
        "            # Save the image data as a TIFF file\n",
        "            tif.imwrite(output_filename, channel_image_data)\n",
        "\n",
        "            print(f'Saved channel {channel_index} to {output_filename}')\n",
        "        else: \n",
        "            # Open the OME-TIFF file and extract the image data for the current channel\n",
        "            # and create chunks of that channel and place in different fov folders\n",
        "            with tif.TiffFile(input_file) as tif_file:\n",
        "                channel_image_data = tif_file.asarray(key=channel_index)\n",
        "                k = 0\n",
        "                height, width = channel_image_data.shape\n",
        "                chunks = []\n",
        "                for i in range(0, height, chunk_size):\n",
        "                    for j in range(0, width, chunk_size):\n",
        "                        chunk = channel_image_data[i:i+chunk_size, j:j+chunk_size]\n",
        "                        if chunk.shape[0] == chunk_size and chunk.shape[1] == chunk_size:\n",
        "                            FOV_dir = os.path.join(tiff_dir, f\"fov{k}\")\n",
        "                            k=k+1                    \n",
        "                            if not os.path.exists(FOV_dir):\n",
        "                                os.makedirs(FOV_dir)\n",
        "                            output_filename = os.path.join(FOV_dir,(f'{channel_names[channel_index]}.tiff'))\n",
        "                            tif.imwrite(output_filename, chunk)\n",
        "            print('Saved channels and chunks in fov subdirectories')\n",
        "        \n",
        "convert_ome_tiff_to_channels(download_file, chunk_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup directory for smaller version and take each tiff from fov0 and generate \n",
        "# smaller version of the file mainly for testing and visualization\n",
        "# regions selected in the top cell\n",
        "\n",
        "# set up file paths\n",
        "# set up the base directory\n",
        "base_dir = project_small_base_dir\n",
        "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
        "cell_table_dir = os.path.join(base_dir, \"segmentation/cell_table\")\n",
        "deepcell_input_dir = os.path.join(base_dir, \"segmentation/deepcell_input\")\n",
        "deepcell_output_dir = os.path.join(base_dir, \"segmentation/deepcell_output\")\n",
        "deepcell_visualization_dir = os.path.join(base_dir, \"segmentation/deepcell_visualization\")\n",
        "\n",
        "# create directories if do not exist\n",
        "for directory in [cell_table_dir, tiff_dir, deepcell_input_dir, deepcell_output_dir, deepcell_visualization_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# validate paths\n",
        "io_utils.validate_paths([base_dir,\n",
        "                         tiff_dir,\n",
        "                         deepcell_input_dir,\n",
        "                         deepcell_output_dir,\n",
        "                         cell_table_dir,\n",
        "                         deepcell_visualization_dir\n",
        "                         ])\n",
        "\n",
        "\n",
        "# Define the input and output directories\n",
        "input_dir = project_base_dir\n",
        "output_dir = project_small_base_dir\n",
        "\n",
        "\n",
        "# Loop through each subdirectory in the input directory\n",
        "for root, dirs, files in os.walk(input_dir):\n",
        "    # Create the corresponding subdirectory in the output directory\n",
        "    output_subdir = os.path.join(output_dir, os.path.relpath(root, input_dir))\n",
        "    os.makedirs(output_subdir, exist_ok=True)\n",
        "\n",
        "    # Loop through each TIFF file in the subdirectory\n",
        "    for file in files:\n",
        "        if file.endswith('.tif') or file.endswith('.tiff'):\n",
        "            # Open the TIFF file and extract the region of interest\n",
        "            input_file = os.path.join(root, file)\n",
        "            with tifffile.TiffFile(input_file) as tif:\n",
        "                img = tif.asarray()\n",
        "                region = img[y1:y2, x1:x2]\n",
        "\n",
        "            # Save the extracted region to a new file in the output directory\n",
        "            output_file = os.path.join(output_subdir, file)\n",
        "            tifffile.imwrite(output_file, region)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iS2jrzWqkwN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## For testing set the base directory to project_small_dir\n",
        "##  otherwise comment it out\n",
        "base_dir = project_base_dir\n",
        "base_dir = project_small_base_dir\n",
        "tiff_dir = os.path.join(base_dir, \"image_data\")\n",
        "cell_table_dir = os.path.join(base_dir, \"segmentation/cell_table\")\n",
        "deepcell_input_dir = os.path.join(base_dir, \"segmentation/deepcell_input\")\n",
        "deepcell_output_dir = os.path.join(base_dir, \"segmentation/deepcell_output\")\n",
        "deepcell_visualization_dir = os.path.join(base_dir, \"segmentation/deepcell_visualization\")"
      ],
      "metadata": {
        "id": "Q1uFZYxbcyRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXAVR4Qb2pD1"
      },
      "source": [
        "### Compute and filter fov paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFbPdI5k2pD1"
      },
      "outputs": [],
      "source": [
        "# either get all fovs in the folder...\n",
        "fovs = io_utils.list_folders(tiff_dir)\n",
        "\n",
        "# ... or optionally, select a specific set of fovs manually\n",
        "#prefix = \"fov\"\n",
        "#fovs = [f\"{prefix}{i}\" for i in range(242,389)]\n",
        "##fovs = [\"fov0\", \"fov1\"]\n",
        "print(fovs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWbPd2JS2pD1"
      },
      "source": [
        "### Load images into notebook, process, and save as Mesmer compatable input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxPi_98G2pD1"
      },
      "outputs": [],
      "source": [
        "# NOTE: at least one of nucs and mems must not be None\n",
        "# nuclear channel name(s) (or nucs = None)\n",
        "nucs = ['DAPI']\n",
        "\n",
        "# membrane channel name(s) (or mems = None)\n",
        "mems = ['CD3', 'CD14']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IagL-Vkj2pD1"
      },
      "outputs": [],
      "source": [
        "# generate and save deepcell input tiffs\n",
        "# set img_sub_folder param to None if the image files in tiff_dir are not in a separate sub folder \n",
        "deepcell_service_utils.generate_deepcell_input(\n",
        "    deepcell_input_dir,\n",
        "    tiff_dir,\n",
        "    nucs,\n",
        "    mems,\n",
        "    fovs,\n",
        "    img_sub_folder=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acHbJsyCFjWf"
      },
      "outputs": [],
      "source": [
        "#prepare the image for mesmer\n",
        "\n",
        "from skimage.io import (imread, imsave)\n",
        "input_file = os.path.join(deepcell_input_dir, 'fov0.tiff')\n",
        "\n",
        "im = imread(input_file)\n",
        "\n",
        "im1 = im[0]\n",
        "im2 = im[1]\n",
        "im = np.stack((im1, im2), axis = -1)\n",
        "im = np.expand_dims(im,0)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepcell.applications import Mesmer\n",
        "from skimage.io import (imread, imsave)\n",
        "\n",
        "image_to_predict = im\n",
        "\n",
        "app = Mesmer()\n",
        "labeled_image = app.predict(image_to_predict)\n",
        "np.save(os.path.join(deepcell_output_dir, 'fov0.npy'), labeled_image)"
      ],
      "metadata": {
        "id": "wzEZ-rNW3KJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepcell.utils.plot_utils import create_rgb_image\n",
        "rgb_images = create_rgb_image(image_to_predict, channel_colors=['green', 'blue'])\n"
      ],
      "metadata": {
        "id": "555GNd28uG1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# select index for displaying\n",
        "idx = 0\n",
        "\n",
        "# plot the data\n",
        "fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
        "ax[0].imshow(image_to_predict[idx, ..., 0])\n",
        "ax[1].imshow(image_to_predict[idx, ..., 1])\n",
        "ax[2].imshow(rgb_images[idx, ...])\n",
        "\n",
        "ax[0].set_title('Nuclear channel')\n",
        "ax[1].set_title('Membrane channel')\n",
        "ax[2].set_title('Overlay')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3T9O57DdvQIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from deepcell.utils.plot_utils import make_outline_overlay\n",
        "overlay_data = make_outline_overlay(rgb_data=rgb_images, predictions=labeled_image)"
      ],
      "metadata": {
        "id": "uIiIxrO2kuDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select index for displaying\n",
        "idx = 0\n",
        "\n",
        "# plot the data\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
        "ax[0].imshow(rgb_images[idx, ...])\n",
        "ax[1].imshow(overlay_data[idx, ...])\n",
        "ax[0].set_title('Raw data')\n",
        "ax[1].set_title('Predictions')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u9WE3A0kwZR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd-uFShr2pD1"
      },
      "source": [
        "## 2: Upload files to Deepcell and download results\n",
        "\n",
        "Deepcell input images will be zipped into a single file, uploaded to [deepcell.org](https://deepcell.org),\n",
        "\n",
        "and the output will be downloaded to the deepcell output directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9fzND5c2pD2"
      },
      "outputs": [],
      "source": [
        "# Mesmer was trained on data acquired at 20X resolution. If your image data was acquired at a different resolution, you will get the best performance by rescaling. The rescale factor will increase or decrease the image resolution by the value you provide. For example, if you data was acquired at 10X, use a `rescale_factor` of 2. If your data was acquired at 60X resolution, use a `rescale_factor` of 0.33.\n",
        "#rescale_factor = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gye92Spd2pD2"
      },
      "outputs": [],
      "source": [
        "## Won't use the Kiosk\n",
        "\n",
        "#deepcell_service_utils.create_deepcell_output(deepcell_input_dir, deepcell_output_dir, fovs=fovs, scale=rescale_factor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN5RyH9e2pD2"
      },
      "source": [
        "### We can then save the segmented mask overlaid on the imaging data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write OME-TIFF\n",
        "from tifffile import imwrite\n",
        "imwrite(os.path.join(deepcell_output_dir, 'fov0_whole_cell.tiff'), overlay_data)\n",
        "#np.save(os.path.join(deepcell_output_dir, 'fov0_whole_cell.tiff'), labeled_image)"
      ],
      "metadata": {
        "id": "MXYc3YdyhJd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSiBKDDV2pD2"
      },
      "outputs": [],
      "source": [
        "# display the channel overlay for a fov, useful for quick verification\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "fov_to_display = io_utils.remove_file_extensions([fovs[0]])[0]\n",
        "\n",
        "fov_overlay = plot_utils.create_overlay(\n",
        "    fov=fov_to_display,\n",
        "    segmentation_dir=deepcell_output_dir,\n",
        "    data_dir=deepcell_input_dir,\n",
        "    img_overlay_chans=['nuclear_channel', 'membrane_channel'],\n",
        "    seg_overlay_comp='whole_cell'\n",
        ")\n",
        "\n",
        "_ = io.imshow(fov_overlay)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fov_to_display)"
      ],
      "metadata": {
        "id": "5wxREhy9eI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf2hM_Ac2pD2"
      },
      "outputs": [],
      "source": [
        "# save the overlaid segmentation labels for each fov (these will not display, but will save in viz_dir)\n",
        "segmentation_utils.save_segmentation_labels(\n",
        "    segmentation_dir=deepcell_output_dir,\n",
        "    data_dir=deepcell_input_dir,\n",
        "    output_dir=deepcell_visualization_dir,\n",
        "    fovs=io_utils.remove_file_extensions(fovs),\n",
        "    channels=['nuclear_channel', 'membrane_channel']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Rh6BBj2pD2"
      },
      "source": [
        "### Afterwards, we can generate expression matrices from the labeling + imaging data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYrTRqQV2pD2"
      },
      "outputs": [],
      "source": [
        "# set to True to add nuclear cell properties to the expression matrix\n",
        "nuclear_counts = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mQq3DzH2pD2"
      },
      "source": [
        "For a full list of features extracted, please refer to the cell table section of: https://ark-analysis.readthedocs.io/en/latest/_rtd/data_types.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGMvzW9S2pD2"
      },
      "outputs": [],
      "source": [
        "# now extract the segmented imaging data to create normalized and transformed expression matrices\n",
        "# note that if you're loading your own dataset, please make sure all the imaging data is in the same folder\n",
        "# with each fov given its own folder and all fovs having the same channels\n",
        "cell_table_size_normalized, cell_table_arcsinh_transformed = \\\n",
        "    marker_quantification.generate_cell_table(segmentation_dir=deepcell_output_dir,\n",
        "                                              tiff_dir=tiff_dir,\n",
        "                                              img_sub_folder=None,\n",
        "                                              fovs=fovs,\n",
        "                                              batch_size=5,\n",
        "                                              nuclear_counts=nuclear_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDrP5gSP2pD2"
      },
      "outputs": [],
      "source": [
        "# Set the compression level if desired, ZSTD compression can offer up to a 60-70% reduction in file size.\n",
        "# NOTE: Compressed `csv` files cannot be opened in Excel. They must be uncompressed beforehand.\n",
        "compression = None\n",
        "\n",
        "# Uncomment the line below to allow for compressed `csv` files.\n",
        "# compression = {\"method\": \"zstd\", \"level\": 3}\n",
        "\n",
        "cell_table_size_normalized.to_csv(os.path.join(cell_table_dir, 'cell_table_size_normalized.csv'),\n",
        "                                  compression=compression, index=False)\n",
        "cell_table_arcsinh_transformed.to_csv(os.path.join(cell_table_dir, 'cell_table_arcsinh_transformed.csv'),\n",
        "                                      compression=compression, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t8q5tA82pD2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "9cd428f2623867f362c6ffd1805d28fe273bb79d15f4a3a73107e7f51d98be79"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}